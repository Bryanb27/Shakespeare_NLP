# Text Preprocessing

## Description

This project was developed for the Text Mining and Analysis course and focuses on comprehensive text preprocessing using Python. It processes the "Shakespeare.txt" file by applying a series of text normalization, tokenization, and analysis techniques.

## Key Features

### 1. Text Normalization
- Converts text to lowercase
- Removes accents and diacritics
- Standardizes acronyms, currencies, dates, and hyphenated words
- Strips punctuation (excluding currency and date-related symbols)
- Eliminates special characters

### 2. Tokenization Techniques
- Basic White Space Tokenization
- NLTK-based Tokenizers: Word, Tree Bank, Word Punctuation, Tweet, and MWE
- TextBlob Word Tokenizer
- spaCy Tokenizer
- Gensim Word Tokenizer
- Keras Tokenization

### 3. Stop-Words Removal
- Remove stop words from the tokenized text

### 4. Text Lemmatization
- Perform lemmatization using the WordNet Lemmatizer

### 5. Text Stemming
- Applies both Porter Stemmer and Snowball Stemmer

### 6. Vocabulary Analysis
- Compares vocabularies generated by lemmatization and stemming
- Outputs the vocabularies as CSV files for further analysis

## Usage

To use this project:

1. **Clone this repository**: Download the project to your local machine.
2. **Install Dependencies**: Ensure Python and the required libraries (e.g., NLTK, TextBlob, spaCy, Gensim) are installed.
3. **Run the Script**: Execute the provided Python script.
4. **Customize as Needed**: Modify file paths or parameters if necessary.
5. **Review Outputs**: Check the output files and directories for the generated results.